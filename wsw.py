# -*- coding: utf-8 -*-
import cv2
import itertools
import time
import os
import sys
import numpy as np
# import easygui as eg

opening = ['1001000110010001011010010110011010010110010010010100101010010010','1100001101101100001111101101001111100001001111101001011101101001']

subtitle_head = """
[Script Info]
; Script generated by Aegisub 3.2.2
; http://www.aegisub.org/
Title: Default Aegisub file
ScriptType: v4.00+
WrapStyle: 0
ScaledBorderAndShadow: yes
YCbCr Matrix: None
PlayResX: 1920
PlayResY: 1080

[Aegisub Project Garbage]
Audio File: $$FILE$$
Video File: $$FILE$$

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,思源黑體,100,&H00FFFFFF,&H00FFFFFF,&H00000000,&H910E0807,-1,0,0,0,100,100,1.14695,0,1,7,4,2,135,135,50,1
Style: 未定义#1,极影毁片圆 Medium,95,&H00FFFFFF,&H00FFFFFF,&H00000000,&H910E0807,0,0,0,0,100,100,1.14695,0,1,7,0,2,135,135,160,1
Style: 开场白,思源黑体 Heavy,120,&H00FFFFFF,&H00FFFFFF,&H00000000,&H910E0807,-1,0,0,0,100,100,1.14695,0,1,7,4,2,135,135,20,1
Style: 旁白#1,极影毁片辉宋 Bold,95,&H00000000,&H00FFFFFF,&H00FFFFFF,&H910E0807,-1,0,0,0,100,100,1.14695,0,1,8,0,2,135,135,160,1
Style: 译注,思源黑体 Heavy,80,&H00FFFFFF,&H00FFFFFF,&H00000000,&H910E0807,-1,0,0,0,100,100,1.14695,0,1,5,2,7,50,0,50,1
Style: 橘红色1,思源黑体,85,&H000E95FA,&H00FFFFFF,&H00081938,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 希迪,思源黑体 Heavy,85,&H0039FFFF,&H00FFFFFF,&H00022F4B,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 土黄色,思源黑体 Heavy,85,&H00A3EBFB,&H00FFFFFF,&H0009353F,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 粉色,思源黑体 Heavy,85,&H00F97CEF,&H00FFFFFF,&H000D2F51,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 蓝色,思源黑体,85,&H00F8968D,&H00FFFFFF,&H002E0303,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 冰雨,思源黑体 Heavy,85,&H00FFFFA2,&H00FFFFFF,&H00613616,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 千夜,思源黑体 Heavy,85,&H00331BF0,&H00FFFFFF,&H000F2434,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 紫色,思源黑体,85,&H00F464BE,&H00FFFFFF,&H00470033,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 灰色1,思源黑体,85,&H007677B7,&H00FFFFFF,&H0006063F,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 其它1,思源黑体 Heavy,85,&H00FFFFFF,&H00FFFFFF,&H00133045,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 其它2,思源黑体,85,&H00FFFFFF,&H00FFFFFF,&H0006063F,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 肉色,思源黑体 Heavy,85,&H00A1A2F7,&H00FFFFFF,&H00121332,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 褐色,思源黑体 Heavy,85,&H0066A9C1,&H00FFFFFF,&H00082331,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 淡绿色,思源黑体 Heavy,85,&H00C4FFB3,&H00FFFFFF,&H001D311D,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 飞蛇,思源黑体,85,&H00CE97C2,&H00FFFFFF,&H00470033,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 墨绿色,思源黑体 Heavy,85,&H00819D5A,&H00FFFFFF,&H00353F0E,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 绿色,思源黑体,85,&H0007FF64,&H00FFFFFF,&H00023D10,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 淡橙色,思源黑体,85,&H00C4FFB4,&H00FFFFFF,&H00470033,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 橘红色,思源黑体 Heavy,85,&H00054FF0,&H00FFFFFF,&H00051536,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: 灰色,思源黑体 Heavy,85,&H00828DA7,&H00FFFFFF,&H0006063F,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1
Style: kuma,思源黑体,85,&H007EBCEF,&H00FFFFFF,&H00163C45,&H00000000,-1,0,0,0,105,100,0,0,1,7,0,2,10,10,115,1


[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""

def phash(img):
    #加载并调整图片为32x32灰度图片
    img = cv2.resize(img, (8, 8), interpolation=cv2.INTER_CUBIC)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = img.astype(np.float32)
    #离散余弦变换
    img = cv2.dct(img)
    hash_str = ''
    img = img[0:8, 0:8]
    avg = sum(img[i, j] for i, j in itertools.product(range(8), range(8)))
    avg = avg/64
    #获得hsah
    for i, j in itertools.product(range(8), range(8)):
        hash_str = f'{hash_str}1' if img[i, j] > avg else f'{hash_str}0'
    return hash_str

def get_color_rate(frame,lower,upper):
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, lower, upper)
    ratio_green = cv2.countNonZero(mask)/(frame.size/3)
    colorPercent = (ratio_green * 100)
    return np.round(colorPercent, 2)

def hamming_distance(str1, str2):
    #计算汉明距离
    if len(str1) != len(str2):
        return 0
    return sum(str1[i] != str2[i] for i in range(len(str1)))

def isset(v): 
    try:
        type(eval(v))
    except NameError:
        return  0
    return  1 


def frames_to_timecode(framerate,frames):
    # 视频 通过视频帧转换成时间|framerate: 视频帧率|frames: 当前视频帧数|return:时间（00:00:01.001）
    return '{0:02d}:{1:02d}:{2:02d}.{3:02d}'.format(int(frames / (3600 * framerate)),
                                                    int(frames / (60 * framerate) % 60),
                                                    int(frames / framerate % 60),
                                                    int(frames / framerate % 1 * 100))

def get_people(img):
    Q_rate_1 = get_color_rate(img,np.array([0,210,245]),np.array([180,210,255]))
    Q_rate_2 = get_color_rate(img,np.array([0,190,195]),np.array([180,200,255]))
    E_rate = get_color_rate(img,np.array([85,95,140]),np.array([95,110,255]))
    W_rate_1 = get_color_rate(img,np.array([15,110,245]),np.array([30,110,255]))
    W_rate_2 = get_color_rate(img,np.array([15,190,245]),np.array([30,210,255]))
    darkgreen_rate = get_color_rate(img,np.array([75,90,135]),np.array([85,210,255]))
    gray_rate = get_color_rate(img,np.array([5,50,155]),np.array([15,75,180]))
    brown_rate = get_color_rate(img,np.array([15,55,180]),np.array([23,135,195]))
    orange_rate = get_color_rate(img,np.array([10,240,240]),np.array([15,255,255]))
    lightgreen_rate = get_color_rate(img,np.array([60,70,235]),np.array([70,90,250]))
    flesh_rate = get_color_rate(img,np.array([0,95,230]),np.array([10,115,255]))
    pink_rate = get_color_rate(img,np.array([145,105,240]),np.array([150,120,255]))
    khaki_rate = get_color_rate(img,np.array([20,75,230]),np.array([25,100,255]))
    
    rate_list = [Q_rate_1,Q_rate_2,W_rate_1,W_rate_2,E_rate,darkgreen_rate,gray_rate,brown_rate,orange_rate,lightgreen_rate,flesh_rate,pink_rate,khaki_rate]
    people_list = ["Q","Q","W","W","E","darkgreen","gray","brown","orange","lightgreen","flesh","pink","khaki"]
    
    max_rate = max(rate_list)
    if(max_rate < 0.2 or len([x for x in rate_list if x > 4]) > 1):
        # print(people_list)
        # print(rate_list)
        return "undefined"
    # return "undefined"
    return people_list[rate_list.index(max_rate)]

def people2style(people):
    style_dict = {
        "Opening":"开场白",
        "undefined":"未定义#1",
        "E":"冰雨",
        "Q":"千夜",
        "W":"希迪",
        "brown":"褐色",
        "darkgreen":"墨绿色",
        "gray":"灰色",
        "orange":"橘红色",
        "lightgreen":"淡绿色",
        "flesh":"肉色",
        "khaki":"土黄色",
        "pink":"粉色",
        "other":"其他1"
        }
    return style_dict[people]

def add_sub(subtext,begintime,endingtime,subpeople):
    global sub_num
    global subtitle
    style = people2style(subpeople)
    subtitle = (
        f'{subtitle}Dialogue: 1,{begintime},{endingtime},{style},{subpeople}'
        + ",0,0,0,,"
        + subtext
        + str(sub_num)
        + "\n"
    )

    sub_num += 1

def add_op(frame_rate,begin_frame_num):
    add_sub("三人经营着的万事屋所在之处是…",frames_to_timecode(frame_rate,begin_frame_num),frames_to_timecode(frame_rate,begin_frame_num+(2.5*frame_rate)),"Opening")
    add_sub("转生到异世界的地球！",frames_to_timecode(frame_rate,begin_frame_num+(2.5*frame_rate)),frames_to_timecode(frame_rate,begin_frame_num+(4.8*frame_rate)),"Opening")
    add_sub("吸血鬼，僵尸—影千夜",frames_to_timecode(frame_rate,begin_frame_num+(4.8*frame_rate)),frames_to_timecode(frame_rate,begin_frame_num+(6.2*frame_rate)),"Opening")
    add_sub("雪女，康娜卡姆依—冰雨",frames_to_timecode(frame_rate,begin_frame_num+(6.2*frame_rate)),frames_to_timecode(frame_rate,begin_frame_num+(7.5*frame_rate)),"Opening")
    add_sub("狼人，荷鲁斯—希迪",frames_to_timecode(frame_rate,begin_frame_num+(7.58*frame_rate)),frames_to_timecode(frame_rate,begin_frame_num+(8.88*frame_rate)),"Opening")
    add_sub("混血万事屋",frames_to_timecode(frame_rate,begin_frame_num+(9.83*frame_rate)),frames_to_timecode(frame_rate,begin_frame_num+(11.5*frame_rate)),"Opening")

# 视频帧总数
current_frame_num = begin_frame_num = last_frame_num = 0
last_pic_hash = ''
op = trans = False
op_match_times = op_bg_num = 0
sub_num = 1
Err = False

def autosub(videopath,subpath):
    start = time.time()
    global op_match_times
    global op
    global trans
    global last_pic_hash
    global current_frame_num
    global begin_frame_num
    global last_frame_num
    global subtitle
    global sub_num
    global current_pic
    global pic_current_hash
    global people_pic
    global people_hash
    global people
    global Err
    subtitle = subtitle_head.replace("$$FILE$$",os.path.abspath(videopath))
    source_video = cv2.VideoCapture(videopath)
    global op_bg_num
    isOpened = bool(source_video.isOpened())
    if isOpened:
        frame_rate = round(source_video.get(5),2)
        while True:
            ret, frame = source_video.read()
            # print(current_frame_num)
            if ret == False:
                break

            current_pic = frame[950:1045,810:910]
            assert 0 not in current_pic.shape, "视频分辨率应为1920*1080"
            pic_current_hash = phash(current_pic)
            hmdistant = hamming_distance(last_pic_hash,pic_current_hash)

            if (op_match_times < 2):
                match_op_pic = frame
                match_op_hash = phash(match_op_pic)
                # print(hamming_distance(match_op_hash,opening[0]))
                if (match_op_hash in opening):
                    if(op_match_times == 0):
                        # print(str(current_frame_num) + " | 开场白起点")
                        op_bg_num = current_frame_num
                        add_op(frame_rate,begin_frame_num)
                    op = bool(1 - op)
                    op_match_times += 1
                    if (op_match_times == 2):
                        # print(str(current_frame_num) + " | 开场白结束")
                        print(f'{op_bg_num} <-> {current_frame_num + int(28 / 17) * frame_rate} | 开场白')

                        begin_frame_num = current_frame_num + int((28/17)*frame_rate)
                        last_frame_num = begin_frame_num
                if(op):
                    current_frame_num += 1
                    # print(match_op_hash)
                    continue

            # print(str(current_frame_num)+" | "+ match_op_hash)
            if ((hmdistant > 13) and (current_frame_num != 0)):
                if (current_frame_num-last_frame_num > (frame_rate/2)):
                    people = get_people(people_pic)

                    print(f'{sub_num} | {current_frame_num-1} <-> {current_frame_num} | hmdst: {hmdistant} | gap: {current_frame_num - last_frame_num} | {frames_to_timecode(frame_rate, begin_frame_num)} --> {frames_to_timecode(frame_rate, current_frame_num)} | people: {people}')

                    add_sub("示范性字幕",frames_to_timecode(frame_rate,begin_frame_num),frames_to_timecode(frame_rate,current_frame_num),people)

                begin_frame_num = current_frame_num
                last_frame_num = current_frame_num

            last_pic_hash = pic_current_hash
            people_pic = frame[940:1060,700:1300]
            people_hash = phash(people_pic)
            current_frame_num += 1
    else:
        print("源视频读取出错")
        Err = True
    print("finish!")
    if(not Err):
        with open(subpath,'w+',encoding='utf-8') as q:
            q.write(subtitle)
    end = time.time()
    print(f'耗时：{str(end - start)}秒')
    return Err


